{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fDncq-aeiiwW",
   "metadata": {
    "id": "fDncq-aeiiwW"
   },
   "source": [
    "---\n",
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fdb2227",
   "metadata": {
    "id": "6fdb2227"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting farasapy\n",
      "  Downloading farasapy-0.0.14-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: tqdm in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from farasapy) (4.59.0)\n",
      "Requirement already satisfied: requests in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from farasapy) (2.25.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from requests->farasapy) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from requests->farasapy) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from requests->farasapy) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from requests->farasapy) (4.0.0)\n",
      "Installing collected packages: farasapy\n",
      "Successfully installed farasapy-0.0.14\n",
      "Collecting Tashaphyne==0.3.4.1\n",
      "  Downloading Tashaphyne-0.3.4.1-py3-none-any.whl (244 kB)\n",
      "\u001b[K     |████████████████████████████████| 244 kB 691 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyarabic\n",
      "  Downloading PyArabic-0.6.14-py3-none-any.whl (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from pyarabic->Tashaphyne==0.3.4.1) (1.15.0)\n",
      "Installing collected packages: pyarabic, Tashaphyne\n",
      "Successfully installed Tashaphyne-0.3.4.1 pyarabic-0.6.14\n",
      "Requirement already satisfied: wordcloud in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from wordcloud) (1.19.5)\n",
      "Requirement already satisfied: matplotlib in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from wordcloud) (3.3.4)\n",
      "Requirement already satisfied: pillow in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from wordcloud) (8.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: six in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.15.0)\n",
      "Collecting ar_wordcloud\n",
      "  Downloading ar_wordcloud-0.0.4-py3-none-any.whl (6.3 kB)\n",
      "Collecting wordcloud>=1.7.0\n",
      "  Downloading wordcloud-1.8.1.tar.gz (220 kB)\n",
      "\u001b[K     |████████████████████████████████| 220 kB 903 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-bidi>=0.4.2\n",
      "  Downloading python_bidi-0.4.2-py2.py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: arabic_reshaper>=2.0.14 in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from ar_wordcloud) (2.1.3)\n",
      "Requirement already satisfied: requests in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from ar_wordcloud) (2.25.1)\n",
      "Requirement already satisfied: setuptools in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from arabic_reshaper>=2.0.14->ar_wordcloud) (52.0.0.post20210125)\n",
      "Requirement already satisfied: future in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from arabic_reshaper>=2.0.14->ar_wordcloud) (0.18.2)\n",
      "Requirement already satisfied: six in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from python-bidi>=0.4.2->ar_wordcloud) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from wordcloud>=1.7.0->ar_wordcloud) (1.19.5)\n",
      "Requirement already satisfied: pillow in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from wordcloud>=1.7.0->ar_wordcloud) (8.2.0)\n",
      "Requirement already satisfied: matplotlib in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from wordcloud>=1.7.0->ar_wordcloud) (3.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud>=1.7.0->ar_wordcloud) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud>=1.7.0->ar_wordcloud) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud>=1.7.0->ar_wordcloud) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud>=1.7.0->ar_wordcloud) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from requests->ar_wordcloud) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from requests->ar_wordcloud) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from requests->ar_wordcloud) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/amalalthaqafi/opt/anaconda3/lib/python3.8/site-packages (from requests->ar_wordcloud) (4.0.0)\n",
      "Building wheels for collected packages: wordcloud\n",
      "  Building wheel for wordcloud (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wordcloud: filename=wordcloud-1.8.1-cp38-cp38-macosx_10_9_x86_64.whl size=158803 sha256=d6b7e89b393619c9b97e4f68124c1f15e26ad78d012d2209cf27cc51be05a695\n",
      "  Stored in directory: /Users/amalalthaqafi/Library/Caches/pip/wheels/4d/3f/0d/a2ba9b7895c9f1be89018b3141c3df3d4f9c786c882ccfbc3b\n",
      "Successfully built wordcloud\n",
      "Installing collected packages: wordcloud, python-bidi, ar-wordcloud\n",
      "  Attempting uninstall: wordcloud\n",
      "    Found existing installation: wordcloud 1.6.0\n",
      "    Uninstalling wordcloud-1.6.0:\n",
      "      Successfully uninstalled wordcloud-1.6.0\n",
      "Successfully installed ar-wordcloud-0.0.4 python-bidi-0.4.2 wordcloud-1.8.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/amalalthaqafi/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/amalalthaqafi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install farasapy\n",
    "# !pip install Tashaphyne==0.3.4.1\n",
    "# !pip install wordcloud\n",
    "# !pip install ar_wordcloud\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b39d777",
   "metadata": {
    "id": "6b39d777"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import string\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report\n",
    "\n",
    "from ar_wordcloud import ArabicWordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vHjWYPq0d62k",
   "metadata": {
    "id": "vHjWYPq0d62k"
   },
   "outputs": [],
   "source": [
    "from tashaphyne.stemming import ArabicLightStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9652b684",
   "metadata": {
    "id": "9652b684"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.isri import ISRIStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80vlPZosboEG",
   "metadata": {
    "id": "80vlPZosboEG"
   },
   "outputs": [],
   "source": [
    "from farasa.pos import FarasaPOSTagger\n",
    "from farasa.ner import FarasaNamedEntityRecognizer\n",
    "from farasa.diacratizer import FarasaDiacritizer\n",
    "from farasa.segmenter import FarasaSegmenter\n",
    "from farasa.stemmer import FarasaStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vu1h1_JCqjJT",
   "metadata": {
    "id": "Vu1h1_JCqjJT"
   },
   "source": [
    "---\n",
    "## Read and exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e73d3e6f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "e73d3e6f",
    "outputId": "47d0701b-846c-4e55-867c-ca59aeb15f91"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aleqtisadiya</td>\n",
       "      <td>هيئة المسح الجيولوجي الأمريكية: زلزال بقوة 6.3...</td>\n",
       "      <td>قالت هيئة المسح الجيولوجي الأمريكيةإن زلزالا ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alweeam</td>\n",
       "      <td>توفر وظائف أكاديمية بجامعــة الملك فيصل</td>\n",
       "      <td>أعلنت جامعة الملك فيصل بالأحساء توفر عدد من ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sabq</td>\n",
       "      <td>&amp;quot;أدبي جدة&amp;quot; يدشن دورة &amp;quot;مفاهيم كت...</td>\n",
       "      <td>سبق- جدة: دشَّن أدبي جدة اللقاء الأول من دورة...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alyaum</td>\n",
       "      <td>قتلة الطموح</td>\n",
       "      <td>«في مجتمعنا مبدأ يمنع تطور الفرد فكرياً واجتم...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alriyadh</td>\n",
       "      <td>دراسة مسببات عدم انخفاض السلع في المملكة بانخف...</td>\n",
       "      <td>أكد الدكتور سليمان السماحي الرئيس التنفيذي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>okaz</td>\n",
       "      <td>تطويق العنف المدرسي ببرنامج «رفق» الإرشادي</td>\n",
       "      <td>تعتزم وزارة التعليم، في مستهل العام الدراسي ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>aawsat</td>\n",
       "      <td>ولي ولي العهد السعودي يتقبل بيعة  منسوبي وزارة...</td>\n",
       "      <td>استقبل الأمير محمد بن سلمان بن عبد العزيز ولي ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>alriyadh</td>\n",
       "      <td>هبوط أول طائرة عسكرية سعودية في مطار عدن بعد د...</td>\n",
       "      <td>هبطت طائرة عسكرية سعودية في مطار مدينة عدن...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>alwatan</td>\n",
       "      <td>استثمار \"الربيعة\" عالميا</td>\n",
       "      <td>هناك دول في العالم تنفق مع شركات علاقات عالمي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>alyaum</td>\n",
       "      <td>غارات للتحالف على مواقع المتمردين وتقدم للمقاو...</td>\n",
       "      <td>قصف طيران التحالف العربي الذي تقوده المملكة ف...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            source                                              title  \\\n",
       "0     aleqtisadiya  هيئة المسح الجيولوجي الأمريكية: زلزال بقوة 6.3...   \n",
       "1          alweeam            توفر وظائف أكاديمية بجامعــة الملك فيصل   \n",
       "2             sabq  &quot;أدبي جدة&quot; يدشن دورة &quot;مفاهيم كت...   \n",
       "3           alyaum                                        قتلة الطموح   \n",
       "4         alriyadh  دراسة مسببات عدم انخفاض السلع في المملكة بانخف...   \n",
       "...            ...                                                ...   \n",
       "9995          okaz         تطويق العنف المدرسي ببرنامج «رفق» الإرشادي   \n",
       "9996        aawsat  ولي ولي العهد السعودي يتقبل بيعة  منسوبي وزارة...   \n",
       "9997      alriyadh  هبوط أول طائرة عسكرية سعودية في مطار عدن بعد د...   \n",
       "9998       alwatan                           استثمار \"الربيعة\" عالميا   \n",
       "9999        alyaum  غارات للتحالف على مواقع المتمردين وتقدم للمقاو...   \n",
       "\n",
       "                                                content  \n",
       "0      قالت هيئة المسح الجيولوجي الأمريكيةإن زلزالا ...  \n",
       "1      أعلنت جامعة الملك فيصل بالأحساء توفر عدد من ا...  \n",
       "2      سبق- جدة: دشَّن أدبي جدة اللقاء الأول من دورة...  \n",
       "3      «في مجتمعنا مبدأ يمنع تطور الفرد فكرياً واجتم...  \n",
       "4         أكد الدكتور سليمان السماحي الرئيس التنفيذي...  \n",
       "...                                                 ...  \n",
       "9995   تعتزم وزارة التعليم، في مستهل العام الدراسي ا...  \n",
       "9996  استقبل الأمير محمد بن سلمان بن عبد العزيز ولي ...  \n",
       "9997      هبطت طائرة عسكرية سعودية في مطار مدينة عدن...  \n",
       "9998   هناك دول في العالم تنفق مع شركات علاقات عالمي...  \n",
       "9999   قصف طيران التحالف العربي الذي تقوده المملكة ف...  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('SaudiNews')\n",
    "df.drop(columns= ['Unnamed: 0'], inplace= True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44a3f989",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44a3f989",
    "outputId": "3f87c01a-1bdb-433f-fb5e-907cbf421ecc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   source   10000 non-null  object\n",
      " 1   title    9978 non-null   object\n",
      " 2   content  9964 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 234.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a59b35de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a59b35de",
    "outputId": "3525eaba-4ff8-4fa7-eab2-092beefea2b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "v6LN1In7rEAj",
   "metadata": {
    "id": "v6LN1In7rEAj"
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cd4b9b",
   "metadata": {
    "id": "b4cd4b9b"
   },
   "source": [
    "---\n",
    "## NLP Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d87e389",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5d87e389",
    "outputId": "c149b0df-8b39-46ae-e655-55981203a14c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26852.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df.content.str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fa90110",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0fa90110",
    "outputId": "679f62bf-8ec7-4455-9310-785894180f49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(df.content.str.len())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FPIDBUqPi-ID",
   "metadata": {
    "id": "FPIDBUqPi-ID"
   },
   "source": [
    "**removing observtions less than 120**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "hPyB8xz-eBbc",
   "metadata": {
    "id": "hPyB8xz-eBbc"
   },
   "outputs": [],
   "source": [
    "df = df[df.content.str.len() > 120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "Ns4PnKE3e4H2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ns4PnKE3e4H2",
    "outputId": "36ec46d0-ad2d-477b-a675-fe0ab4d0f0fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9716, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dbbe880",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9dbbe880",
    "outputId": "85ce87cb-3b7d-49c9-87ba-503c980ccf65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.content.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lFVQh1CvjbTb",
   "metadata": {
    "id": "lFVQh1CvjbTb"
   },
   "source": [
    "### **Removing Non-arabic letters, numbers, amiss typo and special characters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8f129d8",
   "metadata": {
    "id": "c8f129d8"
   },
   "outputs": [],
   "source": [
    "# function to clean and normalize text \n",
    "def clean_text(text):\n",
    "    search = [\"أ\",\"إ\",\"آ\",\"ة\",\"_\",\"-\",\"/\",\".\",\"،\",\" و \",\" يا \",'\"',\"ـ\",\"'\",\"ى\",\"\\\\\",'\\n', '\\t','&quot;','?','؟','!']\n",
    "    replace = [\"ا\",\"ا\",\"ا\",\"ه\",\" \",\" \",\"\",\"\",\"\",\" و\",\" يا\",\"\",\"\",\"\",\"ي\",\"\",' ', ' ',' ',' ? ',' ؟ ',' ! ']  \n",
    "    p_tashkeel = re.compile(r'[\\u0617-\\u061A\\u064B-\\u0652]')\n",
    "    text = re.sub(p_tashkeel,\"\", text)\n",
    "    p_longation = re.compile(r'(.)\\1+')\n",
    "    subst = r\"\\1\\1\"\n",
    "    text = re.sub(p_longation, subst, text)\n",
    "    text = text.replace('وو', 'و')\n",
    "    text = text.replace('يي', 'ي')\n",
    "    text = text.replace('اا', 'ا')\n",
    "    \n",
    "    for i in range(0, len(search)):\n",
    "        text = text.replace(search[i], replace[i])\n",
    "        \n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa5fae7d",
   "metadata": {
    "id": "aa5fae7d"
   },
   "outputs": [],
   "source": [
    "arabic_punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = arabic_punctuations + english_punctuations\n",
    "\n",
    "arabic_diacritics = re.compile(\"\"\"\n",
    "                             ّ    | # Tashdid\n",
    "                             َ    | # Fatha\n",
    "                             ً    | # Tanwin Fath\n",
    "                             ُ    | # Damma\n",
    "                             ٌ    | # Tanwin Damm\n",
    "                             ِ    | # Kasra\n",
    "                             ٍ    | # Tanwin Kasr\n",
    "                             ْ    | # Sukun\n",
    "                             ـ     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)\n",
    "\n",
    "\n",
    "def normalize_arabic(text):\n",
    "    text = re.sub(\"[إأآا]\", \"ا\", text)\n",
    "    text = re.sub(\"ى\", \"ي\", text)\n",
    "    text = re.sub(\"ؤ\", \"ء\", text)\n",
    "    text = re.sub(\"ئ\", \"ء\", text)\n",
    "    text = re.sub(\"ة\", \"ه\", text)\n",
    "    text = re.sub(\"گ\", \"ك\", text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_diacritics(text):\n",
    "    text = re.sub(arabic_diacritics, '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "\n",
    "def remove_repeating_char(text):\n",
    "    return re.sub(r'(.)\\1+', r'\\1', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ca807a3",
   "metadata": {
    "id": "7ca807a3"
   },
   "outputs": [],
   "source": [
    "# clean and normalize text\n",
    "df['content'] = df.content.apply(lambda x: clean_text(x))\n",
    "\n",
    "# remove punctuation\n",
    "df['content'] = df.content.apply(lambda x: remove_punctuations(x))\n",
    "\n",
    "# remove diacritics\n",
    "df['content'] = df.content.apply(lambda x: remove_diacritics(x))\n",
    "\n",
    "# remove repeating char\n",
    "df['content'] = df.content.apply(lambda x: remove_repeating_char(x))\n",
    "\n",
    "# remove english letters\n",
    "df.content = df.content.apply(lambda x: re.sub(r'[a-zA-Z]', '', x))\n",
    "\n",
    "# remove a special character _\n",
    "df.content = df.content.apply(lambda x: re.sub(r'[_]+', '', x))\n",
    "\n",
    "# remove space\n",
    "df['content'] = df.content.str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a8b6730",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "3a8b6730",
    "outputId": "90f00869-22a0-4969-97d0-b505bde01087",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aleqtisadiya</td>\n",
       "      <td>هيئة المسح الجيولوجي الأمريكية: زلزال بقوة 6.3...</td>\n",
       "      <td>قالت هيئه المسح الجيولوجي الامريكيهان زلزالا ب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alweeam</td>\n",
       "      <td>توفر وظائف أكاديمية بجامعــة الملك فيصل</td>\n",
       "      <td>اعلنت جامعه الملك فيصل بالاحساء توفر عد من الو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sabq</td>\n",
       "      <td>&amp;quot;أدبي جدة&amp;quot; يدشن دورة &amp;quot;مفاهيم كت...</td>\n",
       "      <td>سبق جده دشن ادبي جده القاء الاول من دوره مفاهي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alyaum</td>\n",
       "      <td>قتلة الطموح</td>\n",
       "      <td>«في مجتمعنا مبدا يمنع تطور الفرد فكريا واجتماع...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alriyadh</td>\n",
       "      <td>دراسة مسببات عدم انخفاض السلع في المملكة بانخف...</td>\n",
       "      <td>اكد الدكتور سليمان السماحي الرئيس التنفيذي لجم...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>okaz</td>\n",
       "      <td>تطويق العنف المدرسي ببرنامج «رفق» الإرشادي</td>\n",
       "      <td>تعتزم وزاره التعليم في مستهل العام الدراسي الم...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>aawsat</td>\n",
       "      <td>ولي ولي العهد السعودي يتقبل بيعة  منسوبي وزارة...</td>\n",
       "      <td>استقبل الامير محمد بن سلمان بن عبد العزيز ولي ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>alriyadh</td>\n",
       "      <td>هبوط أول طائرة عسكرية سعودية في مطار عدن بعد د...</td>\n",
       "      <td>هبطت طائره عسكريه سعوديه في مطار مدينه عدن جنو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>alwatan</td>\n",
       "      <td>استثمار \"الربيعة\" عالميا</td>\n",
       "      <td>هناك دول في العالم تنفق مع شركات علاقات عالميه...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>alyaum</td>\n",
       "      <td>غارات للتحالف على مواقع المتمردين وتقدم للمقاو...</td>\n",
       "      <td>قصف طيران التحالف العربي الذي تقوده الملكه في ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9716 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            source                                              title  \\\n",
       "0     aleqtisadiya  هيئة المسح الجيولوجي الأمريكية: زلزال بقوة 6.3...   \n",
       "1          alweeam            توفر وظائف أكاديمية بجامعــة الملك فيصل   \n",
       "2             sabq  &quot;أدبي جدة&quot; يدشن دورة &quot;مفاهيم كت...   \n",
       "3           alyaum                                        قتلة الطموح   \n",
       "4         alriyadh  دراسة مسببات عدم انخفاض السلع في المملكة بانخف...   \n",
       "...            ...                                                ...   \n",
       "9995          okaz         تطويق العنف المدرسي ببرنامج «رفق» الإرشادي   \n",
       "9996        aawsat  ولي ولي العهد السعودي يتقبل بيعة  منسوبي وزارة...   \n",
       "9997      alriyadh  هبوط أول طائرة عسكرية سعودية في مطار عدن بعد د...   \n",
       "9998       alwatan                           استثمار \"الربيعة\" عالميا   \n",
       "9999        alyaum  غارات للتحالف على مواقع المتمردين وتقدم للمقاو...   \n",
       "\n",
       "                                                content  \n",
       "0     قالت هيئه المسح الجيولوجي الامريكيهان زلزالا ب...  \n",
       "1     اعلنت جامعه الملك فيصل بالاحساء توفر عد من الو...  \n",
       "2     سبق جده دشن ادبي جده القاء الاول من دوره مفاهي...  \n",
       "3     «في مجتمعنا مبدا يمنع تطور الفرد فكريا واجتماع...  \n",
       "4     اكد الدكتور سليمان السماحي الرئيس التنفيذي لجم...  \n",
       "...                                                 ...  \n",
       "9995  تعتزم وزاره التعليم في مستهل العام الدراسي الم...  \n",
       "9996  استقبل الامير محمد بن سلمان بن عبد العزيز ولي ...  \n",
       "9997  هبطت طائره عسكريه سعوديه في مطار مدينه عدن جنو...  \n",
       "9998  هناك دول في العالم تنفق مع شركات علاقات عالميه...  \n",
       "9999  قصف طيران التحالف العربي الذي تقوده الملكه في ...  \n",
       "\n",
       "[9716 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b23460cd",
   "metadata": {
    "id": "b23460cd"
   },
   "outputs": [],
   "source": [
    "# Convert to list\n",
    "data = df[df.columns[2]].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-da5-Sj1lSn_",
   "metadata": {
    "id": "-da5-Sj1lSn_"
   },
   "source": [
    "### **Stemming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aTX9N-pOZYqg",
   "metadata": {
    "id": "aTX9N-pOZYqg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-12-27 19:27:56,104 - farasapy_logger - ERROR]: error occured: Command '['java', '-version']' returned non-zero exit status 1..\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "We could not check for java version on the machine. Please make sure you have installed Java 1.7+ and add it to your PATH.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/farasa/__base.py\u001b[0m in \u001b[0;36m_check_java_version\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             version_proc_output = subprocess.check_output(\n\u001b[0m\u001b[1;32m    145\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0;34m\"java\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-version\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTDOUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0m\u001b[1;32m    416\u001b[0m                **kwargs).stdout\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             raise CalledProcessError(retcode, process.args,\n\u001b[0m\u001b[1;32m    517\u001b[0m                                      output=stdout, stderr=stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['java', '-version']' returned non-zero exit status 1.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-83087036bf2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfarasa_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFarasaStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/farasa/__base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, interactive, logging_level)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"perform system check...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"check java version...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_java_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"check toolkit binaries...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_toolkit_binaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/farasa/__base.py\u001b[0m in \u001b[0;36m_check_java_version\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mproc_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"error occured: {proc_err}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             raise Exception(\n\u001b[0m\u001b[1;32m    163\u001b[0m                 \u001b[0;34m\"We could not check for java version on the machine. Please make sure you have installed Java 1.7+ and add it to your PATH.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             )\n",
      "\u001b[0;31mException\u001b[0m: We could not check for java version on the machine. Please make sure you have installed Java 1.7+ and add it to your PATH."
     ]
    }
   ],
   "source": [
    "farasa_st = FarasaStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FITFl71ZcyVB",
   "metadata": {
    "id": "FITFl71ZcyVB"
   },
   "outputs": [],
   "source": [
    "# st = ISRIStemmer()\n",
    "# ArListem = ArabicLightStemmer()\n",
    "\n",
    "# def stemSentence(sentence):\n",
    "#     token_words=word_tokenize(sentence)\n",
    "#     stem_sentence=[]\n",
    "#     for word in token_words:\n",
    "#         stem_sentence.append(farasa_st.stem(word))\n",
    "#         #stem_sentence.append(ArListem.light_stem(word))\n",
    "#         stem_sentence.append(' ')\n",
    "#     return \"\".join(stem_sentence)\n",
    "\n",
    "# df.content = df.content.apply(lambda x: stemSentence(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F4ZqQ5GdljxO",
   "metadata": {
    "id": "F4ZqQ5GdljxO"
   },
   "source": [
    "### **TF-IDF Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ElkLLT_ef4BW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "ElkLLT_ef4BW",
    "outputId": "fa8d7c68-7ef1-4aea-f7ee-86f02b952891"
   },
   "outputs": [],
   "source": [
    "# the document-term matrix \n",
    "arb_stopwords = set(nltk.corpus.stopwords.words('arabic'))\n",
    "tfidf = TfidfVectorizer(stop_words=arb_stopwords)\n",
    "doc_words = tfidf.fit_transform(df.content)\n",
    "pd.DataFrame(doc_words.toarray(),columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7311f93e",
   "metadata": {
    "id": "7311f93e"
   },
   "outputs": [],
   "source": [
    "# # To display full text\n",
    "# pd.set_option('display.max_colwidth',-1)#can see the whole data on one single row\n",
    "# complaints_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Jh0hO3a3iRbp",
   "metadata": {
    "id": "Jh0hO3a3iRbp"
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sAmVigPOiWbR",
   "metadata": {
    "id": "sAmVigPOiWbR"
   },
   "outputs": [],
   "source": [
    "# print WordCloud visualization\n",
    "\n",
    "awc = ArabicWordCloud(background_color=\"black\",)\n",
    "\n",
    "mpl.rcParams['figure.figsize']=(20,12.0)  \n",
    "mpl.rcParams['font.size']=12            \n",
    "mpl.rcParams['savefig.dpi']=100             \n",
    "mpl.rcParams['figure.subplot.bottom']=.1 \n",
    "\n",
    "# wordcloud = awc.generate(str(tfidf.get_feature_names())).from_text(\n",
    "#     str(tfidf.get_feature_names()))\n",
    "\n",
    "wordcloud = awc.generate(str(tfidf.get_feature_names())).from_text(str(tfidf.get_feature_names()))\n",
    "\n",
    "print(wordcloud)\n",
    "fig = plt.figure(1)\n",
    "plt.imshow(wordcloud.recolor(colormap='Dark2'),interpolation='bilinear')\n",
    "#plt.title(\"Word Cloud of all the words\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "G3i1y6gqtODf",
   "metadata": {
    "id": "G3i1y6gqtODf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "nlp-saudi-news.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
